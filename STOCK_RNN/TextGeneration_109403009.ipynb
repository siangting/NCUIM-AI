{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-109403009.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3f258f-8608-46ae-b111-31e0b2a7924c"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "\n",
        "!gdown --id 1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe --output \"./Eileen_Legendary.txt\"\n",
        "\n",
        "# !wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe\n",
            "To: /content/Eileen_Legendary.txt\n",
            "100% 818k/818k [00:00<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mbvzh_9_Tz8",
        "outputId": "4622b6bd-a290-4a2a-8260-01f9997903d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"/content/You_Are_the_Apple_of_My_Eye.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"《那些年，我們一起追的女孩》共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "《那些年，我們一起追的女孩》共有 97045 字詞\n",
            "包含了 2722 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一七年五月五日版》\n",
            "《好讀書櫃》典藏版\n",
            "內容簡介\n",
            "「歷時三年構思、一年籌備、十個月的拍攝與後製，電影奮力走出了小說，躍上了大銀幕。我也終於學會，不用傷口，就記住青春裡最重要的事。這場戰鬥獻給你們，一路支持我的讀者。獻給，我的女孩。」──九把刀\n",
            "男孩用電影打造了時光機，只為了再一次與女孩相遇。\n",
            "8/19，帶著你的命中註定，走進電影院，再一次收藏青春\n",
            "我將一句話遺留在青春裡。\n",
            "現在，我想跟妳說……\n",
            "多年以後，故事，終於找到了重新開始的方法\n",
            "胡鬧搞怪？\n",
            "叛逆熱血？\n",
            "對抗無聊的大人？\n",
            "不，\n",
            "我的青春，都是妳。\n",
            "一場名為青春的潮水淹沒了我們。\n",
            "浪退時，渾身溼透的我們一起坐在沙灘上，\n",
            "看著我們最喜愛的女孩子用力揮舞雙手，幸福踏向人生的另一端。\n",
            "下一次浪來，會帶走女孩留在沙灘上的美好足跡。\n",
            "但我們還在。\n",
            "刻在我們心中的女孩模樣，也還會在。\n",
            "豪情不減，嘻笑當年。\n",
            "作者簡介\n",
            "九把刀（1978年8月25日─），本名柯景騰（Giddens Ko），台灣作家，彰化縣人。國立交通大學管理科學系學士，東海大學社會學系碩士。群星瑞智國際藝能有限公司所屬。因提交小說做為論文資料的一部分，發現自己適合從事寫作，\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "2ba5a13f-9ecb-45cd-8c1e-e7dc7c77e19f"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 1137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "b9f9c3a6-120c-459c-ba4c-afce0856f23c"
      },
      "source": [
        "print(f\"原本《那些年，我們一起追的女孩》共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本《那些年，我們一起追的女孩》共有 97045 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘92167個字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "94efc769-ba40-4b86-c029-278ea1602029"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '○', '一', '七', '年', '五', '月', '五', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '典', '藏', '版', '\\n', '內', '容', '簡', '介', '\\n', '「', '歷', '時', '三', '年', '構', '思', '、', '一', '年', '備', '、']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{642, 1028, 1035, 800, 424, 1068, 688, 827, 59, 828, 829, 60, 704, 198, 839, 199, 713, 1100, 594, 1109, 867, 1129, 1002, 1131, 1132, 236, 748, 886, 380}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "58208a76-9d67-4fd0-d5a6-740e5c3b97f2"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[1132  827  828   59 1131  688 1028  800  867  800  839  236  829 1132\n",
            "  827 1109  704 1035  829  380  198], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '○', '一', '七', '年', '五', '月', '五', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '典', '藏']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[ 236 1132  642  713  748  199 1132 1129  424 1100 1002 1028   60  886\n",
            " 1068 1131 1028  594 1068  960 1120], shape=(21,), dtype=int32)\n",
            "['版', '\\n', '內', '容', '簡', '介', '\\n', '「', '歷', '時', '三', '年', '構', '思', '、', '一', '年', '備', '、', '十', '個']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "5b0e0a19-c3c1-4956-8c4b-104734e714f2"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "9543e1ed-5807-4459-dafe-8f9b2a6d6de7"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['\\n', '《', '二', '○', '一', '七', '年', '五', '月', '五', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '典']\n",
            "Target: ['《', '二', '○', '一', '七', '年', '五', '月', '五', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '典', '藏']\n",
            "--------------------------------------------------\n",
            "Input : [1132  827  828   59 1131  688 1028  800  867  800  839  236  829 1132\n",
            "  827 1109  704 1035  829  380]\n",
            "Target: [ 827  828   59 1131  688 1028  800  867  800  839  236  829 1132  827\n",
            " 1109  704 1035  829  380  198]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "84199b05-9faf-4f4d-a50b-4e0f96ed6c5e"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "989ba533-4a63-4aab-9fb8-f4d03095befe"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 512)         582144    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 1137)        2329713   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 128,765,553\n",
            "Trainable params: 128,765,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "6a2a9a36-dc3b-4eed-d10b-8608efbcbabf"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 1137)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "26e6bff0-e39c-4684-ed34-28320b7a28ac"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "承認我心中暗暗高興「比賽終於要結束，我也\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "踢哪告臉運漢漢漢強右右右臉臉臉臉臉臉靦惑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "7b17b970-7bd4-4d79-f2d7-9b454763f3f7"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "68/68 [==============================] - 24s 308ms/step - loss: 6.1621\n",
            "Epoch 2/20\n",
            "68/68 [==============================] - 22s 315ms/step - loss: 5.6837\n",
            "Epoch 3/20\n",
            "68/68 [==============================] - 22s 325ms/step - loss: 5.3429\n",
            "Epoch 4/20\n",
            "68/68 [==============================] - 23s 329ms/step - loss: 5.0895\n",
            "Epoch 5/20\n",
            "68/68 [==============================] - 23s 337ms/step - loss: 4.8978\n",
            "Epoch 6/20\n",
            "68/68 [==============================] - 24s 344ms/step - loss: 4.7193\n",
            "Epoch 7/20\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 4.5443\n",
            "Epoch 8/20\n",
            "68/68 [==============================] - 24s 348ms/step - loss: 4.3714\n",
            "Epoch 9/20\n",
            "68/68 [==============================] - 24s 354ms/step - loss: 4.1948\n",
            "Epoch 10/20\n",
            "68/68 [==============================] - 25s 363ms/step - loss: 4.0150\n",
            "Epoch 11/20\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 3.8066\n",
            "Epoch 12/20\n",
            "68/68 [==============================] - 25s 360ms/step - loss: 3.5763\n",
            "Epoch 13/20\n",
            "68/68 [==============================] - 24s 351ms/step - loss: 3.3124\n",
            "Epoch 14/20\n",
            "68/68 [==============================] - 24s 347ms/step - loss: 3.0044\n",
            "Epoch 15/20\n",
            "68/68 [==============================] - 24s 350ms/step - loss: 2.6437\n",
            "Epoch 16/20\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 2.2235\n",
            "Epoch 17/20\n",
            "68/68 [==============================] - 24s 348ms/step - loss: 1.7619\n",
            "Epoch 18/20\n",
            "68/68 [==============================] - 24s 357ms/step - loss: 1.2882\n",
            "Epoch 19/20\n",
            "68/68 [==============================] - 24s 351ms/step - loss: 0.8481\n",
            "Epoch 20/20\n",
            "68/68 [==============================] - 24s 351ms/step - loss: 0.5273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f1f72c55-7c84-4d48-9331-e8adfe4bd3de"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3elbMNg4z4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda078a8-43f3-4258-bea1-dd217991a955"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "承認我心中暗暗高興「比賽終於要結束，我也\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "認我心中暗暗高興「比賽終於要結束，我也可\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b20e4a6-1315-48b3-a543-1695c8ed753b"
      },
      "source": [
        "init_seq = \"男孩\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "男孩的好朋友：超有義氣，分文未取。然而我真的不想意思，也要被我家面裏的一切都很久，因為我帶的不是重點，再怎麼介都不會比你們？我們一起追的女孩」與手指鍵盤共時，就是這麼一點點。\n",
            "我們兩個人的身線與沈佳儀發現在喜歡沈佳儀的男孩，可以我們的生命裏也會在這裏課本她家的自己，都有一個對不。」\n",
            "「我想大學畢業嗎？」我站起，伸了個若有所思的「絕對區，但我的手卻自己很喜歡沈佳儀。」許博淳跟我刻意坐在桌子上裝睡。\n",
            "「你們男生的時候，你可以去打打打電話給李小華問，討論起婚禮結束。\n",
            "回到學校，男生五年，女生五小隊，男生五小隊，活動的內容一跟佛學生生，等到宿舍的廣場。\n",
            "「等到聯考，這麼辦。」我著鼻孔，看著她的頭短髮。\n",
            "「我覺得只要……」\n",
            "「……」\n",
            "「我又沒有要做到。」\n",
            "「我又沒有要做到死穴！」許博淳說，長了我的想法。\n",
            "「就這樣，錯你的比人還真不錯。」我沒有所思，著小耳朵。\n",
            "「靠，你去死啦！」許博淳說，長了我的想法。\n",
            "「就這樣喔？」我著下巴，心不在看著講臺上說道。\n",
            "「不是，我這樣會做到。」\n",
            "「我又不要跟沈佳儀說，我可能會機你追她說話！」\n",
            "「……」我從爾地看著肩。\n",
            "「我想，你跟你說，但你一定會沒有辦法。」\n",
            "「我想念復"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "# 不要執行這一個block\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273a39b8-ed46-4c2c-e77d-905b6e427c69"
      },
      "source": [
        "init_seq = \"女孩\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "女孩「花、台」兩地相隔的苦境。他們小口僅僅用功用功，在日中的「還有一點，上上國中就是不可能的地方，每次下課就會打電話給沈佳儀，幸好接電話的正是沈佳儀與我之間的自己，已經可以養家我們的去。\n",
            "「對了，我這次會做不到，我就這麼愛上跟我們一起洗的女孩淑，成績非常難受，卻很高興的句。\n",
            "有一天，我不能再回頭。\n",
            "我非常滿足地欣賞，沈佳儀研究我刻著甜筒。\n",
            "「不要，我根本沒有在生手。」沈佳儀一個字一個字說，一個個幸的冷笑。\n",
            "「怒啊，那我自己看著辦。」我著頭，不用自己的語氣。\n",
            "「不要那麼，我們一定會有你自己。」我起肉片大口說，一邊在電話。\n",
            "「……」\n",
            "「我想念。」\n",
            "「我又沒有要做到。」許博淳說，長了我的想法。\n",
            "「……」我。\n",
            "「我想得，我一定會到你，你都不會再做什麼啦？」許博淳有些反。\n",
            "「你不是說一定要在第一天，但我還是沒有說，但我的手再也得認真。\n",
            "真正認識，只要踏力一點，就是我們這個男生最大的一行。\n",
            "這樣不斷的房間，我在一起也不奇怪的事，例如在抽屜裏種花，把考卷成細的紙片當花到處亂在同學頭上。此外，我老是在找人陪我到走外打毛球，流流沒有聯考壓力。\n",
            "「……」我。\n",
            "我來下腳踏車，阿和在跟我交中時候去去學校念書，以後用可能竹的樣子就在一起，很多義氣卻默不住。\n",
            "我玩下，誤以於有時間，我台中口離，不斷足到我對繞的。\n",
            "有一次愛情，我都能能無法克制的望。\n",
            "我終於擁有，我只是大家在一起。\n",
            "「我也沒辦法，你就只能說，我們一起追的女孩」與手指鍵盤打，看著沈佳儀頗有好感，隱遇下我心頭的。\n",
            "有一點，我還是無法迴避我跟沈佳儀的交情，我還是越來越高，卻越容易上手的，有時候大家才會結束，讓我無法收，不約而我。\n",
            "「對了，我跟許博淳還是我笑了出來。」許博淳說，拿著紙牌環顧四周。\n",
            "「哈哈，對我的青春，從我自己都會害怕啊。」我嘻嘻笑，一點也沒子。\n",
            "「你沒有你自己。」許博淳有些吃驚的表情。\n",
            "「不是，我是個性。」我說，看著手指上印著甜筒。\n",
            "「不會，你是這樣說沒錯，但你最好深呼吸一下。」許博淳倒，忍不住提醒我的肩。\n",
            "「我也不想跟沈佳儀講話耶。」怪獸坐在樹下。\n",
            "「我也有你不知道的一面啊，我的女孩都會真的蠻可思議！」許博淳哼哼坐下，排好陣頭。\n",
            "「不要，我根本沒有人會死。」我著鼻孔。\n",
            "「不要，我剛剛已經點了……」\n",
            "沈佳儀。\n",
            "「……」沈佳儀停下腳步，可是她的眼神。\n",
            "「我也不想，你跟沈佳儀只是喜歡聊，一個人一個新約特好的朋友。\n",
            "我們兩個人，沈佳"
          ]
        }
      ]
    }
  ]
}